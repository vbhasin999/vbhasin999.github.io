<!DOCTYPE HTML>
<!--
	Story by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Vedant Bhasin</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
		<link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.5.0/css/all.css">
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper" class="divided">

				<!-- One -->
					<section class="banner style1 orient-left content-align-left image-position-right fullscreen onload-image-fade-in onload-content-fade-right">
						<div class="content">
							<h1>Vedant Bhasin</h1>
							<p class="major">Welcome to my site! I'm a dedicated deep learning practitioner, with a strong background in speech, vision, multimodal, and reinforcement learning applications. My hands-on experience includes prototyping and optimizing neural models at Carnegie Mellon, where I also worked as a teaching assisstant. Skilled in Python, I'm proficient in using tools like Scikit-Learn and PyTorch for building and optimizing models. I'm driven by the possibilities of machine learning to address complex problems and inspire innovation. Take a look around to see the work I'm excited about and the projects I've brought to life.</p>
							<ul class="icons">
								<li><a href="https://www.linkedin.com/in/vedant-bhasin/" target="_blank" class="icon brands style2 fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://github.com/vbhasin999" target="_blank" class="icon brands style2 fa-github"><span class="label">Github</span></a></li>
								<li>
									<a href="https://huggingface.co/vbhasin" target="_blank" class="icon brands style2 fa-github" style="position: relative;">
									  <img src="images/hf-logo.png" alt="Hugging Face" style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 1.75em; height: 1.75em;">
									  <span class="label">Hugging Face</span>
									</a>
								</li>
								<li><a href="https://www.kaggle.com/vedantbhasin" target="_blank" class="icon brands style2 fa-kaggle"><span class="label">Kaggle</span></a></li>
								<li><a href="mailto:vedantbhasin@cmu.edu" class="icon style2 fa-envelope"><span class="label">Email</span></a></li>
								<li><a href="assets/docs/vedant_bhasin.pdf" target="_blank" class="icon style2 fa-file"><span class="label">Email</span></a></li>
								
							</ul>
							<!-- <ul class="actions stacked">
								<li><a href="#first" class="button big wide smooth-scroll-middle">Get Started</a></li>
							</ul> -->
						</div>
						<div class="image">
							<img src="images/pfp3.jpg" alt="" />
						</div>
						
					</section>

				<!-- Two -->
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in" id="first">
						<div class="content">
							<h2>Fine Grained Image Grounding for Visual Abductive Reasoning</h2>
							<p>In this project, we tackled the challenge of fine-grained image grounding in the context of Visual Abductive Reasoning (VAR). VAR is a process where a system makes logical inferences from visual data, deducing the most likely explanation for what is seen. Utilizing the Sherlock dataset, our goal was to enhance the interpretative abilities of Vision-Language Models (VLMs). We achieved this by integrating panoptic scene graphs, created from image bounding boxes, into the BLIP-2 model. This integration allowed the model to gain a deeper understanding of complex visual contexts. Our results showed a significant improvement in the model's retreival capabilities, confirming the effectiveness of our approach in advancing the capabilities of VLMs in visual abductive reasoning.</p>
							<ul class="actions">
								<li><a href="assets/docs/multimodal_final_report.pdf" target="_blank" class="button icon solid fa-file">Paper</a></li>
								<li><a href="assets/docs/multimodal_poster.pdf" target="_blank"class="button icon solid fa-image">Poster</a></li>
								<li><a href="https://github.com/vbhasin999/MMQA" target="_blank" class="button icon solid brands fa-github">Code</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="images/segmented.jpeg" alt="" />
						</div>
					</section>

				<!-- Three -->
					<section class="spotlight style1 orient-left content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Turtle Duel</h2>
							<p>Vertical scroller game where the player controls the main character to jump on randomly generated platforms while avoiding enemy characters and falling down. The game also features rudimentary AI, which detects the nearest safe platform to move to, as well as detecting enemy characters.</p>
							<ul class="actions">
								<li><a href="https://github.com/vbhasin999/112-Doodle-Jump-TP" target="_blank" class="button icon solid brands fa-github">Code</a></li>
							</ul>
							<iframe style="width: 100%; aspect-ratio: 4 / 3; height: auto;" src="https://www.youtube.com/embed/GpPHu8sspqY?si=RKvCAlOZw55eqosJ&amp;start=198&end=120" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
							
						</div>
						<div class="image">
							<img src="images/raphael.png" style="max-width: 100%; max-height: 100%; object-fit: contain;background-color: red" alt="" />
						</div>

					</section>

				<!-- Four -->
					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Adapting Multilingual Vision-Language Models for Code Mixed VQA</h2>
							<p>In this project, we focused on enhancing multilingual Vision-Language models for code-mixing - the blending of multiple languages in a single sentence. This is especially challenging for VQA systems. My work involved fine-tuning the mBLIP model on datasets like HinGE and MCVQA to better handle the nuances of code-mixed languages. We experimented with novel fine-tuning approaches, significantly improving the model's accuracy in understanding and responding to code-mixed queries, paving the way for advancements in code mixed natural language processing</p>
							<ul class="actions">
								<li><a href="assets/docs/ANLP_Final_Report.pdf" target="_blank" class="button icon solid fa-file">Paper</a></li>
								<li><a href="assets/docs/ANLP_poster.pdf" target="_blank"class="button icon solid fa-image">Poster</a></li>
								<li><a href="https://github.com/vbhasin999/MMQA" target="_blank" class="button icon solid brands fa-github">Code</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="images/anlp_enhanced.png" style="max-width: 100%; max-height: 100%; object-fit: contain;background-color: white" alt="" />
						</div>
					</section>

					<section class="spotlight style1 orient-left content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Symphony AI</h2>
							<p>In this project, we created a system where users can play guitar and receive AI-generated piano accompaniment in real-time. Using a pre-trained REMI transformer model, the system analyzes guitar play and produces matching piano melodies, offering a seamless and interactive musical experience for both amateur and seasoned musicians.</p>
							<ul class="actions">
								<li><a href="assets/docs/D5_Poster_18500_S23.pdf" target="_blank" class="button">Poster</a></li>
							</ul>
							<iframe style="width: 100%; aspect-ratio: 16 / 9; height: auto;" src="https://www.youtube.com/embed/pZ2HogiQPQU?si=k59aRHhhmX-Pz_h-" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
						</div>
						<div class="image">
							<img src="images/symphony_ai.png" style="max-width: 100%; max-height: 100%; object-fit: contain;background-color: rgb(250, 245, 235)" alt="" />
						</div>
					</section>

					<section class="spotlight style1 orient-right content-align-left image-position-center onscroll-image-fade-in">
						<div class="content">
							<h2>Facial Recognition</h2>
							<p>
								This project showcases a face verification and classification system using the VGG2 dataset. It features a modified ConvNext CNN architecture paired with ArcFace loss to address two key challenges: face classification and face verification. The modified ConvNext CNN is tailored for facial recognition tasks, enhancing its effectiveness in classifying faces. Meanwhile, ArcFace loss is employed as a contrastive loss for verification, mapping facial features into an embedding space for accurate similarity assessment. This approach results in high accuracy for both classification and verification, producing robust facial embeddings suitable for various applications.</p>
							<ul class="actions">
								<li><a href="https://github.com/vbhasin999/CNN_face_recognition" target="_blank" class="button icon solid brands fa-github">Code</a></li>
							</ul>
						</div>
						<div class="image">
							<img src="images/VGG_face.jpeg" style="max-width: 100%; max-height: 100%; object-fit: contain;background-color: white" alt="" />
						</div>
					</section>

				<!-- Five -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Timeline</h2>
							<p>A brief timeline which showcases some important milestones from my academic and professional journey.</p>
						</div>

						<!-- Gallery -->
							<div class="gallery style2 medium lightbox onscroll-fade-in">
								<article>
									<a href="images/insdc.png" class="image">
										<img src="images/insdc.png" height="292" alt="" />
									</a>
									<div class="caption">
										<h3>Summer '19</h3>
										<p>Graduated highschool with a 42/45 in the IBDP program. While in school I served as the first speaker for the debate team, bass player for inter and intra school events, and volunteer for various social initiatives.</p>
										<!-- <ul class="actions fixed">
											<li><span class="button small">Details</span></li>
										</ul> -->
									</div>
								</article>
								<article>
									<a href="images/frat.png" class="image">
										<img src="images/frat.png" height="292" alt="" />
									</a>
									<div class="caption">
										<h3>Spring '22</h3>
										<p>Elected as vice president for Carnegie Mellon's chapter of the Sigma Chi Fraternity. Managed the executive committee and spearheaded the planning, organization, and execution of social and philanthropic events</p>
									</div>
								</article>
								<article>
									<a href="images/axaitech-2.png" class="image" >
										<img src="images/axaitech-2.png" height="292" alt=""/>
									</a>
									<div class="caption">
										<h3>Summer '22</h3>
										<p>AI & Data Science Intern for Axaitech, a biotechnology company based in Cape Town. Researched and prototyped different classification approaches for cancer diagnosis using gene expression data. </p>
										
									</div>
								</article>
								<article>
									<a href="images/lti.png" class="image">
										<img src="images/lti.png" height="292" style="background-color: white;" alt="" />
									</a>
									<div class="caption">
										<h3>Spring '23</h3>
										<p>Teaching Assisstant for CMU's flagship deep learning course under Dr. Bhiksha Raj. Performed ablation studies, conducted recitations, and served as a mentor for student led projects.</p>
										
									</div>
								</article>
								<article>
									<a href="images/grad-crop.png" class="image">
										<img src="images/grad-crop.png" height="292" alt="" />
									</a>
									<div class="caption">
										<h3>Spring '23</h3>
										<p>Graduated with my Bachelor's degree in Electrical & Computer Engineering</p>
									</div>
								</article>
							</div>

					</section>

				<!-- Six -->
					<section class="wrapper style1 align-center">
						<div class="inner">
							<h2>Core Technical Competencies</h2>
							<p>My skill set has developed through a blend of extensive coursework, hands-on project work, and valuable internship experience. With a focus on diverse Machine Learning fields such as Deep Learning, Reinforcement Learning, Natural Language Processing, Computer Vision, and Multimodal ML, I've developed a unique breadth in AI. This is complemented by solid software development expertise in Python and a strong foundation in Computer Systems and Distributed Systems. My comprehensive approach not only covers a wide range of ML techniques but also ensures robust implementation through deep software and systems knowledge.</p>
							<div class="items style1 medium onscroll-fade-in">
								<section>
									<span class="icon solid style2 major fa-circle-nodes"></span>
									<h3>Deep Learning</h3>
									<p>PyTorch, GCP, AWS, Colab</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-chart-line"></span>
									<h3>Computer Vision</h3>
									<p>torchvision</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-robot"></span>
									<h3>Reinforcement Learning</h3>
									<p>PyTorch, Open AI Gym</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-comments"></span>
									<h3>Natural Language Processing</h3>
									<p>PyTorch-NLP, HuggingFace</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-eye"></span>
									<h3>Data Science &<br /> Machine Learning</h3>
									<p>Scikit-learn, Pandas, Seaborn</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-brain"></span>
									<h3>Multimodal Machine Learning</h3>
									<p>PyTorch, PyTorch-NLP, Torchvision</p>
								</section>
								<section>
									<span class="icon style2 major brands fa-python"></span>
									<h3>Software Development</h3>
									<p>Python, C, C++</p>
								</section>
								<section>
									<span class="icon solid style2 major brands fa-html5"></span>
									<h3>Web Applications</h3>
									<p>HTML/CSS, jQuery, JavaScript, Django</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-solid fa-database"></span>
									<h3>Relational Databases</h3>
									<p>PostgreSQL</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-cloud"></span>
									<h3>Cloud Computing</h3>
									<p>AWS, GCP, C, Java</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-solid fa-microchip"></span>
									<h3>Computer Systems</h3>
									<p>C</p>
								</section>
								<section>
									<span class="icon solid style2 major fa-network-wired"></span>
									<h3>Distributed Systems</h3>
									<p>C, C++, Java</p>
								</section>
								
							</div>
						</div>
					</section>

				<!-- Footer -->
					<footer class="wrapper style1 align-center">
						<div class="inner">
							<ul class="icons">
								<li><a href="https://www.linkedin.com/in/vedant-bhasin/" target="_blank" class="icon brands style2 fa-linkedin-in"><span class="label">LinkedIn</span></a></li>
								<li><a href="https://github.com/vbhasin999" target="_blank" class="icon brands style2 fa-github"><span class="label">Github</span></a></li>
								<li>
									<a href="https://huggingface.co/vbhasin" target="_blank" class="icon brands style2 fa-github" style="position: relative;">
									  <img src="images/hf-logo.png" alt="Hugging Face" style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); width: 1.75em; height: 1.75em;">
									  <span class="label">Hugging Face</span>
									</a>
								</li>
								<li><a href="https://www.kaggle.com/vedantbhasin" target="_blank" class="icon brands style2 fa-kaggle"><span class="label">Kaggle</span></a></li>
								<li><a href="mailto:vedantbhasin@cmu.edu" class="icon style2 fa-envelope"><span class="label">Email</span></a></li>
								<li><a href="assets/docs/vedant_bhasin.pdf" target="_blank" class="icon style2 fa-file"><span class="label">Email</span></a></li>
							</ul>
							<p>&copy; Vedant Bhasin. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
						</div>
					</footer>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.scrollex.min.js"></script>
			<script src="assets/js/jquery.scrolly.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>